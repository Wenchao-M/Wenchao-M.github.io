<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wenchao Ma (马文超) </title>


  <meta name="author" content="Wenchao Ma(马文超)">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/none.png">
</head>

<body>
  <table style="width:100%;max-width:900px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name> Wenchao Ma (马文超)</name>


             <p>I am a third-year Ph.D. student in the College of Information Sciences and Technology at the Pennsylvania State University, advised by <a href="https://faculty.ist.psu.edu/suh972/">Prof. Sharon Xiaolei Huang</a>. Previously, I received my master's degree in Computer Science from Wuhan University, where I worked with <a href="https://xuenan.net/">Dr. Nan Xue</a>, and my bachelor's degree in Software Engineering from Chongqing University.
             </p>
               <br>
              <p>My research interests lie in computer vision and computer graphics, particularly in character animation, human motion reconstruction, and scene generation. </p>

              <br>
              <p style="text-align:center">
                <a href="mailto:wmm5390@psu.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=QkZwuWwAAAAJ&hl=zh-CN&oi=sra">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/Wenchao-M/">Github</a>&nbsp/&nbsp
                <a href="https://www.linkedin.com/in/wenchao-ma-7205042bb/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/me.png"><img style="width:80%;max-width:100%" alt="profile photo" src="images/me.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

         <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Experience</heading>
              <p>
               <strong>Roblox</strong>, 
	       </br><strong>Research Intern</strong>, May. 2025 to Aug. 2025
              </p>
              <p>
                <strong>Roblox</strong>, 
          </br><strong>Research Intern</strong>, May. 2024 to Aug. 2024
          </p>
              <p>
                <strong>NetEase</strong>
          </br><strong>Research Intern</strong>, Dec.2022 to Apr.2023
          </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            </td>
          </tr>
        </tbody></table>

        <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publication</heading>
              <p>
               * denotes equal contribution
              </p>
        <p>
                </br> RigAnyFace: Scaling Neural Facial Mesh Auto-Rigging with Unlabeled Data
         </br>  <strong>Wenchao Ma*</strong>, Dario Kneubühler*, Maurice Chu, Ian Sachs, Haomiao Jiang, Sharon Xiaolei Huang
              </br>[<a href="https://openreview.net/pdf?id=alrbY3gwNB"> Paper </a>] [<a href="https://wenchao-m.github.io/RigAnyFace.github.io/">Project Page</a>] [<a>Code (coming soon)</a>]
              </br>
               Advances in Neural Information Processing Systems (<em>NeurIPS</em>), 2025.
              <br>
              </p>  
         <p>

        <p>
                </br> GaussianFlow: Splatting Gaussian Dynamics for 4D Content Creation
         </br>  Quankai Gao, Qiangeng Xu, Zhe Cao, Ben Mildenhall, <strong>Wenchao Ma</strong>, Le Chen, Danhang Tang, Ulrich Neumann. 
              </br>[<a href="https://arxiv.org/pdf/2403.12365.pdf">Paper</a>] [<a href="https://github.com/Zerg-Overmind/GaussianFlow">Code</a>] [<a href="https://zerg-overmind.github.io/GaussianFlow.github.io/">Project page</a>]
              </br>
              Transactions on Machine Learning Research (<em>TMLR</em>), 2025.
              <br>
              </p>  

         <p>

        <p>
                </br> Enhancing AI-assisted Stroke Emergency Triage with Adaptive Uncertainty Estimation. 
         </br>  Shuhua Yang*, Tongan Cai*, Haomiao Ni*, <strong>Wenchao Ma</strong>, Yuan Xue, Kelvin Wong, John Volpi, James Z. Wang, Sharon Xiaolei Huang, Stephen T.C. Wong.
              </br>[<a href="http://infolab.stanford.edu/~wangz/project/imsearch/MEDICAL/MICCAI25/yang.pdf">Paper</a>] [<a href="https://github.com/shuashua0608/AUSTIN">Code</a>]
              </br> 
              International Conference on Medical Image Computing and Computer Assisted Intervention (<em>MICCAI</em>), 2025.
              <br>
              </p>  

         <p>

          <p>
          </br> Learning Conditional Space-Time Prompt Distributions for Video Class-Incremental Learning.
        </br>  Xiaohan Zou,  <strong>Wenchao Ma</strong>, Shu Zhao.
              </br>[<a href="http://openaccess.thecvf.com/content/CVPR2025/papers/Zou_Learning_Conditional_Space-Time_Prompt_Distributions_for_Video_Class-Incremental_Learning_CVPR_2025_paper.pdf">Paper</a>]
              </br>
              IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em>CVPR</em>), 2025 <font color="#FF0000">(Highlight)</font>
              <br>
        </p>  

          <p>
          </br> SafeTriage: Facial Video De-identification for Privacy-Preserving Stroke Triage
        </br>  Tongan Cai*, Haomiao Ni*, <strong>Wenchao Ma*</strong>, Yuan Xue, Qian Ma, Rachel Leicht, Kelvin Wong, John Volpi, Stephen T.C. Wong, James Z. Wang, Sharon Xiaolei Huang
          </br>[<a href="https://arxiv.org/pdf/2506.16578">Paper</a>]
          </br>
          Information Processing in Medical Imaging (<em>IPMI</em>), 2025
          <br>
          </p>  

          <p>
          </br> KALAHash: Knowledge-Anchored Low-Resource Adaptation for Deep Hashing
        </br>  Shu Zhao, Tan Yu, Xiaoshuai Hao, <strong>Wenchao Ma</strong>, Vijaykrishnan Narayanan
        </br>[<a href="https://arxiv.org/pdf/2412.19417">Paper</a>] [<a href="https://github.com/Tree-Shu-Zhao/KALAHash.pytorch">Code</a>]
          </br>
          AAAI Conference on Artificial Intelligence (<em>AAAI</em>), 2025
          <br>
          </p>  

   <p>
                </br> Stratified Avatar Generation from Sparse Observations.
         </br>  Han Feng*, <strong>Wenchao Ma*</strong>, Quankai Gao, Xianwei Zheng, Nan Xue, Huijuan Xu.
              </br>[<a href="https://arxiv.org/abs/2405.20786">Paper</a>] [<a href="https://github.com/Wenchao-M/SAGE">Code</a>] [<a href="https://fhan235.github.io/SAGENet/index.html">Project page</a>] 
              </br>
              IEEE/CVF Conference on Computer Vision and Pattern Recognition (<em>CVPR</em>), 2024 <font color="#FF0000">(Oral)</font>
              <br>
              </p>  


	      <p>
                </br> HoW-3D: Holistic 3D Wireframe Perception from a Single Image.
	       </br> <strong>Wenchao Ma</strong>, Bin Tan, Nan Xue, Tianfu Wu, Xianwei Zheng, Gui-Song Xia.
              </br>[<a href="https://arxiv.org/abs/2208.06999">Paper</a>] [<a href="https://github.com/Wenchao-M/HoW-3D">Code</a>] [<a href="https://www.youtube.com/watch?v=27EEcG-LnJM">Video</a>]
              </br>
              International Conference on 3D Vision (<em>3DV</em>), 2022
              <br>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>

